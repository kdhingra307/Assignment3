{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tuple_to_dict:\n",
    "    \n",
    "    def __init__(self, tuple_object):\n",
    "        self.tuple = tuple_object\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tuple)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            \"input\" : self.tuple[index][0],\n",
    "            \"target\" : self.tuple[index][1],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist(train=False):\n",
    "    from torchvision import datasets, transforms\n",
    "    return tuple_to_dict(datasets.MNIST(\"./resources/data/raw\", train=train, transform=transforms.Compose([transforms.Grayscale(num_output_channels=3),transforms.Resize([32, 32]), transforms.ToTensor()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnist_m:\n",
    "    \n",
    "    def __init__(self, path, train=False):\n",
    "        \n",
    "        if train:\n",
    "            self.files = open(path+\"/mnist_m_train_labels.txt\").read().split(\"\\n\")[:-1]\n",
    "            self.path = path + \"/mnist_m_train/\"\n",
    "        else:\n",
    "            self.files = open(path+\"/mnist_m_test_labels.txt\").read().split(\"\\n\")[:-1]\n",
    "            self.path = path + \"/mnist_m_test/\"\n",
    "        \n",
    "        print(\"Fetching {} files\".format(len(self.files)))\n",
    "        \n",
    "        self.data = []\n",
    "        for e in self.files:\n",
    "            ee = e.split(\" \")\n",
    "            self.data.append({\n",
    "                \"input\" : ee[0],\n",
    "                \"target\" : int(ee[1])\n",
    "            })\n",
    "        \n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.path + self.data[index]['input'])\n",
    "        \n",
    "        return {\n",
    "            \"input\" : self.transform(image),\n",
    "            \"target\" : self.data[index]['target']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 59001 files\n",
      "Fetching 9001 files\n"
     ]
    }
   ],
   "source": [
    "dataset = {\n",
    "    \"train\" :{\n",
    "        \"mnist\" : torch.utils.data.DataLoader(get_mnist(train=True), batch_size=64, drop_last=True),\n",
    "        \"mnist_m\" : torch.utils.data.DataLoader(mnist_m(\"resources/data/raw/mnist_m/\", train=True), batch_size=64,drop_last=True),\n",
    "    },\n",
    "    \"test\" : {\n",
    "        \"mnist\" : torch.utils.data.DataLoader(get_mnist(train=False), batch_size=64,drop_last=True),\n",
    "        \"mnist_m\" : torch.utils.data.DataLoader(mnist_m(\"resources/data/raw/mnist_m/\", train=False), batch_size=64, drop_last=True),\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "class grl_grad(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return input\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return -1*grad_output\n",
    "\n",
    "\n",
    "\n",
    "class grl(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(grl, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return grl_grad.apply(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(torch.nn.Module):        \n",
    "    \n",
    "    def __encoder__(self):\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(kernel_size=5, in_channels=3, out_channels=32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            torch.nn.Conv2d(kernel_size=5, in_channels=32, out_channels=48),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "    \n",
    "    def __classifier__(self):\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=self.encoder_shape, out_features=100),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=100, out_features=100),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=100, out_features=10),\n",
    "        )\n",
    "    \n",
    "    def __domain__(self):\n",
    "        self.domain =  torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=self.encoder_shape, out_features=100),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=100, out_features=1),\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def __init__(self,):\n",
    "        super(model, self).__init__()\n",
    "        self.encoder_shape = 48*5*5   \n",
    "        self.__encoder__()\n",
    "        self.__classifier__()\n",
    "        self.grl = grl()\n",
    "        self.__domain__()\n",
    "    \n",
    "    \n",
    "    def forward(self, x, split=False):\n",
    "        encoded = self.encoder(x).reshape([-1, self.encoder_shape])\n",
    "        batch_size = encoded.shape[0]\n",
    "        start_index = 0\n",
    "        end_index = batch_size// 2\n",
    "        \n",
    "        if split:\n",
    "            start_index = end_index\n",
    "            end_index= batch_size\n",
    "        \n",
    "        return {\n",
    "                \"classifier\" : self.classifier(encoded[start_index:end_index]),\n",
    "                \"domain\" : self.domain(self.grl(encoded)).squeeze(-1)\n",
    "            }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_stats(stats, model, step):\n",
    "    trainer.tensorboard_writer.add_scalar(\"loss/epoch/{}\".format(model), np.mean(stats['loss']), step)\n",
    "    trainer.tensorboard_writer.add_scalar(\"acc/epoch/{}/domain\".format(model), np.mean(stats['acc']['domain']), step)\n",
    "    trainer.tensorboard_writer.add_scalar(\"acc/epoch/{}/classifier\".format(model), np.mean(stats['acc']['classifier']), step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train:\n",
    "    \n",
    "    def __init__(self, model_to_train):\n",
    "        self.model = model_to_train()\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "        self.model.to(self.device)\n",
    "        self.loss = {\n",
    "            \"logistic\" : torch.nn.BCEWithLogitsLoss(),\n",
    "            \"softmax\" : torch.nn.CrossEntropyLoss(),\n",
    "        }\n",
    "        self.optimizer = torch.optim.SGD(lr=0.01, momentum=0.9, params=self.model.parameters())\n",
    "#         self.scheduler = torch.optim.lr_scheduler.LambdaLR(self.optimizer, lambda step:0.01/((1+step/100)**0.75), last_epoch=-1)\n",
    "        self.step = 0\n",
    "        self.__get_tensorboard()\n",
    "    \n",
    "    def loop(self, X, to_cpu=False):\n",
    "        X = X.to(self.device)\n",
    "        if to_cpu:\n",
    "            return self.model(X).detach()\n",
    "        return self.model(X)\n",
    "    \n",
    "    def compute_loss(self, X, output):\n",
    "        lam = (2/(1+np.exp(-1*self.step/10))) - 1\n",
    "        loss = self.loss['softmax'](target=X['target']['classifier'], input=output['classifier'])\n",
    "        loss += lam*self.loss['logistic'](target=X['target']['domain'], input=output['domain'])\n",
    "        return loss\n",
    "    \n",
    "    def stats(self, X):\n",
    "        output = self.loop(X['input'])\n",
    "        loss = self.compute_loss(X, output)\n",
    "        classifier_acc = np.count_nonzero(torch.nn.functional.softmax(output['classifier'], dim=-1).argmax(-1).cpu().numpy() == X['target']['classifier'].cpu().numpy())/len(X['target']['classifier'])\n",
    "        target_out = self.model(X['input'], split=True)\n",
    "        domain_acc = np.count_nonzero(torch.nn.functional.softmax(target_out['classifier'], dim=-1).argmax(-1).cpu().numpy() == X['target']['domain_classifier'].cpu().numpy())/len(X['target']['domain_classifier'])\n",
    "        \n",
    "        return {\n",
    "            \"acc\" : {\n",
    "                \"classifier\" : classifier_acc,\n",
    "                \"domain\" : domain_acc,\n",
    "            },\n",
    "            \"loss\" : loss.item()\n",
    "        }\n",
    "    \n",
    "    def cycle(self, X):\n",
    "        self.optimizer.zero_grad()\n",
    "        output = self.loop(X['input'])\n",
    "        cur_loss = self.compute_loss(X, output)\n",
    "        cur_loss.backward()\n",
    "        self.optimizer.step()\n",
    "#         self.scheduler.step()\n",
    "        return cur_loss\n",
    "    \n",
    "    \n",
    "    def get_X(self, mnist_batch, mnist_m_batch):\n",
    "        \n",
    "        mnist_batch_size = mnist_batch['input'].shape[0]\n",
    "        mnist_m_batch_size = mnist_m_batch['input'].shape[0]\n",
    "        \n",
    "        return {\n",
    "            \"input\" : torch.cat([mnist_batch['input'], mnist_m_batch['input']], axis=0).to(self.device),\n",
    "            \"target\" : {\n",
    "                \"classifier\" : mnist_batch['target'].to(self.device),\n",
    "                \"domain\" : torch.cat([torch.ones(mnist_batch_size), torch.zeros(mnist_m_batch_size)], axis=0).to(self.device),\n",
    "                \"domain_classifier\" : mnist_m_batch['target'].to(self.device)\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def batch(self, mnist_batch, mnist_m_batch, task):\n",
    "        \n",
    "        X = self.get_X(mnist_batch, mnist_m_batch)        \n",
    "        if task:\n",
    "            return self.cycle(X)\n",
    "        else:\n",
    "            return self.stats(X)\n",
    "    \n",
    "    def __get_tensorboard(self):\n",
    "        from torch.utils.tensorboard import SummaryWriter\n",
    "        from datetime import datetime\n",
    "\n",
    "        task_type = \"MNIST\"\n",
    "        time_date = \"{}\".format(datetime.now())\n",
    "        self.tensorboard_writer = SummaryWriter(\"log/{}/{}\".format(task_type, time_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d589e5380949eebc75b602ebf76017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_acc = 0\n",
    "for epoch in tqdm(range(1000)):\n",
    "    \n",
    "    mnist_m_iter = dataset['train']['mnist_m'].__iter__()\n",
    "    for mnist_batch in dataset['train']['mnist']:\n",
    "        \n",
    "        mnist_m_batch = next(mnist_m_iter, None)\n",
    "        if mnist_m_batch is None:\n",
    "            mnist_m_iter = dataset['train']['mnist_m'].__iter__()\n",
    "            mnist_m_batch = next(mnist_m_iter, None)\n",
    "            \n",
    "        loss = trainer.batch(mnist_batch, mnist_m_batch, True)\n",
    "        trainer.tensorboard_writer.add_scalar(\"loss/batch/train\", loss.item())\n",
    "    trainer.step+=1\n",
    "    \n",
    "    stats = {\n",
    "        \"loss\":[],\n",
    "        \"acc\" : {\n",
    "            \"domain\":[],\n",
    "            \"classifier\":[]\n",
    "        }\n",
    "    }\n",
    "    mnist_m_iter = dataset['train']['mnist_m'].__iter__()\n",
    "    for mnist_batch in dataset['train']['mnist']:\n",
    "        \n",
    "        mnist_m_batch = next(mnist_m_iter, None)\n",
    "        if mnist_m_batch is None:\n",
    "            mnist_m_iter = dataset['train']['mnist_m'].__iter__()\n",
    "            mnist_m_batch = next(mnist_m_iter, None)        \n",
    "        \n",
    "        batch_stats = trainer.batch(mnist_batch, mnist_m_batch, False)\n",
    "        stats['loss'].append(batch_stats['loss'])\n",
    "        stats['acc']['domain'].append(batch_stats['acc']['domain'])\n",
    "        stats['acc']['classifier'].append(batch_stats['acc']['classifier'])\n",
    "    \n",
    "    write_stats(stats, \"train\", epoch)\n",
    "    \n",
    "    stats = {\n",
    "        \"loss\":[],\n",
    "        \"acc\" : {\n",
    "            \"domain\":[],\n",
    "            \"classifier\":[]\n",
    "        }\n",
    "    }\n",
    "    mnist_m_iter = dataset['test']['mnist_m'].__iter__()\n",
    "    for mnist_batch in dataset['test']['mnist']:\n",
    "        \n",
    "        mnist_m_batch = next(mnist_m_iter, None)\n",
    "        if mnist_m_batch is None:\n",
    "            mnist_m_iter = dataset['test']['mnist_m'].__iter__()\n",
    "            mnist_m_batch = next(mnist_m_iter, None)        \n",
    "        \n",
    "        batch_stats = trainer.batch(mnist_batch, mnist_m_batch, False)\n",
    "        stats['loss'].append(batch_stats['loss'])\n",
    "        stats['acc']['domain'].append(batch_stats['acc']['domain'])\n",
    "        stats['acc']['classifier'].append(batch_stats['acc']['classifier'])\n",
    "    \n",
    "    write_stats(stats, \"test\", epoch)\n",
    "    \n",
    "    \n",
    "    if np.mean(stats['acc']['domain']) > best_acc:\n",
    "        torch.save(trainer.model.state_dict(), \"./weights/model_{}\".format(epoch))\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.tensorboard_writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = trainer.get_X(mnist_batch, mnist_m_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = trainer.loop(X['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False,  True, False, False, False,  True,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.softmax(output['classifier'], dim=-1).argmax(-1).cpu().numpy() == X['target']['classifier'].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 4, 4, 0, 9, 3, 5, 8, 9, 7, 4, 5, 4, 8, 3, 2, 7, 1, 3, 7, 9, 3, 2, 5,\n",
       "        4, 5, 2, 9, 7, 1, 4, 2, 7, 1, 6, 3, 9, 8, 3, 6, 4, 4, 1, 9, 6, 4, 3, 9,\n",
       "        1, 2, 9, 0, 7, 0, 0, 4, 8, 4, 3, 6, 3, 2, 6, 5], device='cuda:0')"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['target']['domain_classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5ad9d69c50>"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X['input'][65].transpose(0, 2).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = (2/(1+np.exp(-1*0/100))) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
